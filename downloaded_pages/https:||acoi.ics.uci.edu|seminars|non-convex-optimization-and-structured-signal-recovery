












ACO Center @ UCI  




Algorithms, Combinatorics and Optimization 













 Search





















Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 

 Menu


Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 

















Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 

 Menu


Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 














Non-Convex Optimization and Structured Signal Recovery
Home>Seminars>Non-Convex Optimization and Structured Signal Recovery















Non-Convex Optimization and Structured Signal Recovery 




Date: November 1, 2018					





Time: 2:00 pm					





Room: DBH 4011					





Speaker: Babak Hassibi 					





				 (Caltech)					











































Abstract: In the past couple of decades, non-smooth convex optimization has emerged as a powerful tool for the recovery of structured signals (sparse, low rank, finite constellation, etc.) from possibly noisy measurements in a variety of applications in statistics, signal processing and machine learning. While the algorithms (basis pursuit, LASSO, etc.) are often fairly well established, rigorous frameworks for the exact analysis of the performance of such methods are only just emerging. The talk will introduce and describe a fairly general theory for how to determine the performance (minimum number of measurements, mean-square-error, probability-of-error, etc.) of such methods for various measurement ensembles (Gaussian, Haar, etc.). The framework enables one to assess the performance of these methods before actual implementation and allows one to optimally choose parameters such as regularizer coefficients, number of measurements, etc. The theory subsumes earlier results as special cases. It builds on an inconspicuous 1962 lemma of Slepian (for comparing Gaussian processes), as well as on a non-trivial generalization due to Gordon in 1988, and produces concepts from convex geometry (such as Gaussian widths and Moreau envelopes) in a very natural way. The talk will also consider extensions to certain non-Gaussian settings and their applications in massive MIMO, one-bit compressed sensing, graphical LASSO, and phase retrieval.






Bio: Babak Hassibi is the inaugural Mose and Lillian S. Bohn Professor of Electrical Engineering at the California Institute of Technology, where he has been since 2001, From 2011 to 2016 he was the Gordon M Binder/Amgen Professor of Electrical Engineering and during 2008-2015 he was Executive Officer of Electrical Engineering, as well as Associate Director of Information Science and Technology. Prior to Caltech, he was a Member of the Technical Staff in the Mathematical Sciences Research Center at Bell Laboratories, Murray Hill, NJ. He obtained his PhD degree from Stanford University in 1996 and his BS degree from the University of Tehran in 1989. His research interests span various aspects of information theory, communications, signal processing, control and machine learning. He is an ISI highly cited author in Computer Science and, among other awards, is the recipient of the US Presidential Early Career Award for Scientists and Engineers (PECASE) and the David and Lucille Packard Fellowship in Science and Engineering.





























ACO Center @ UCI • Privacy Policy • © 2022 UC Regents 

















ACO Center @ UCI  




Algorithms, Combinatorics and Optimization 













 Search





















Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 

 Menu


Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 

















Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 

 Menu


Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 














Non-Convex Optimization and Structured Signal Recovery
Home>Seminars>Non-Convex Optimization and Structured Signal Recovery















Non-Convex Optimization and Structured Signal Recovery 




Date: November 1, 2018					





Time: 2:00 pm					





Room: DBH 4011					





Speaker: Babak Hassibi 					





				 (Caltech)					











































Abstract: In the past couple of decades, non-smooth convex optimization has emerged as a powerful tool for the recovery of structured signals (sparse, low rank, finite constellation, etc.) from possibly noisy measurements in a variety of applications in statistics, signal processing and machine learning. While the algorithms (basis pursuit, LASSO, etc.) are often fairly well established, rigorous frameworks for the exact analysis of the performance of such methods are only just emerging. The talk will introduce and describe a fairly general theory for how to determine the performance (minimum number of measurements, mean-square-error, probability-of-error, etc.) of such methods for various measurement ensembles (Gaussian, Haar, etc.). The framework enables one to assess the performance of these methods before actual implementation and allows one to optimally choose parameters such as regularizer coefficients, number of measurements, etc. The theory subsumes earlier results as special cases. It builds on an inconspicuous 1962 lemma of Slepian (for comparing Gaussian processes), as well as on a non-trivial generalization due to Gordon in 1988, and produces concepts from convex geometry (such as Gaussian widths and Moreau envelopes) in a very natural way. The talk will also consider extensions to certain non-Gaussian settings and their applications in massive MIMO, one-bit compressed sensing, graphical LASSO, and phase retrieval.






Bio: Babak Hassibi is the inaugural Mose and Lillian S. Bohn Professor of Electrical Engineering at the California Institute of Technology, where he has been since 2001, From 2011 to 2016 he was the Gordon M Binder/Amgen Professor of Electrical Engineering and during 2008-2015 he was Executive Officer of Electrical Engineering, as well as Associate Director of Information Science and Technology. Prior to Caltech, he was a Member of the Technical Staff in the Mathematical Sciences Research Center at Bell Laboratories, Murray Hill, NJ. He obtained his PhD degree from Stanford University in 1996 and his BS degree from the University of Tehran in 1989. His research interests span various aspects of information theory, communications, signal processing, control and machine learning. He is an ISI highly cited author in Computer Science and, among other awards, is the recipient of the US Presidential Early Career Award for Scientists and Engineers (PECASE) and the David and Lucille Packard Fellowship in Science and Engineering.





























ACO Center @ UCI • Privacy Policy • © 2022 UC Regents 














ACO Center @ UCI  




Algorithms, Combinatorics and Optimization 













 Search





















Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 

 Menu


Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 

















Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 

 Menu


Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 


















ACO Center @ UCI  




Algorithms, Combinatorics and Optimization 













 Search





















Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 

 Menu


Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 

















Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 

 Menu


Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 















ACO Center @ UCI  




Algorithms, Combinatorics and Optimization 













 Search
















ACO Center @ UCI  




Algorithms, Combinatorics and Optimization 













 Search














ACO Center @ UCI  




Algorithms, Combinatorics and Optimization 








ACO Center @ UCI  




Algorithms, Combinatorics and Optimization 






ACO Center @ UCI  




Algorithms, Combinatorics and Optimization 




ACO Center @ UCI  

ACO Center @ UCI  


Algorithms, Combinatorics and Optimization 



Algorithms, Combinatorics and Optimization 

Algorithms, Combinatorics and Optimization Algorithms, Combinatorics and Optimization







 Search















 Search













 Search











 Search









 Search






 Search



 Search
Search







Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 

 Menu


Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 













Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 

 Menu


Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 











Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 

 Menu


Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 









Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 

 Menu


Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 







Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 

 Menu


Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 





Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 

 Menu


Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 



Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 

 Menu


Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 
HomePeopleSeminar SeriesSynergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation

ICSMathBusiness SchoolIMBSEECSCenter for Algorithms and Theory of ComputationNewsContact
 Menu
MenuHomePeopleSeminar SeriesSynergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation

ICSMathBusiness SchoolIMBSEECSCenter for Algorithms and Theory of ComputationNewsContact







Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 

 Menu


Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 













Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 

 Menu


Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 











Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 

 Menu


Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 









Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 

 Menu


Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 







Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 

 Menu


Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 





Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 

 Menu


Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 



Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 

 Menu


Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 
HomePeopleSeminar SeriesSynergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation

ICSMathBusiness SchoolIMBSEECSCenter for Algorithms and Theory of ComputationNewsContact
 Menu
MenuHomePeopleSeminar SeriesSynergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation

ICSMathBusiness SchoolIMBSEECSCenter for Algorithms and Theory of ComputationNewsContact
Non-Convex Optimization and Structured Signal Recovery
Home>Seminars>Non-Convex Optimization and Structured Signal Recovery
Home>HomeHome>Seminars>Seminars>Non-Convex Optimization and Structured Signal RecoveryNon-Convex Optimization and Structured Signal Recovery












Non-Convex Optimization and Structured Signal Recovery 




Date: November 1, 2018					





Time: 2:00 pm					





Room: DBH 4011					





Speaker: Babak Hassibi 					





				 (Caltech)					











































Abstract: In the past couple of decades, non-smooth convex optimization has emerged as a powerful tool for the recovery of structured signals (sparse, low rank, finite constellation, etc.) from possibly noisy measurements in a variety of applications in statistics, signal processing and machine learning. While the algorithms (basis pursuit, LASSO, etc.) are often fairly well established, rigorous frameworks for the exact analysis of the performance of such methods are only just emerging. The talk will introduce and describe a fairly general theory for how to determine the performance (minimum number of measurements, mean-square-error, probability-of-error, etc.) of such methods for various measurement ensembles (Gaussian, Haar, etc.). The framework enables one to assess the performance of these methods before actual implementation and allows one to optimally choose parameters such as regularizer coefficients, number of measurements, etc. The theory subsumes earlier results as special cases. It builds on an inconspicuous 1962 lemma of Slepian (for comparing Gaussian processes), as well as on a non-trivial generalization due to Gordon in 1988, and produces concepts from convex geometry (such as Gaussian widths and Moreau envelopes) in a very natural way. The talk will also consider extensions to certain non-Gaussian settings and their applications in massive MIMO, one-bit compressed sensing, graphical LASSO, and phase retrieval.






Bio: Babak Hassibi is the inaugural Mose and Lillian S. Bohn Professor of Electrical Engineering at the California Institute of Technology, where he has been since 2001, From 2011 to 2016 he was the Gordon M Binder/Amgen Professor of Electrical Engineering and during 2008-2015 he was Executive Officer of Electrical Engineering, as well as Associate Director of Information Science and Technology. Prior to Caltech, he was a Member of the Technical Staff in the Mathematical Sciences Research Center at Bell Laboratories, Murray Hill, NJ. He obtained his PhD degree from Stanford University in 1996 and his BS degree from the University of Tehran in 1989. His research interests span various aspects of information theory, communications, signal processing, control and machine learning. He is an ISI highly cited author in Computer Science and, among other awards, is the recipient of the US Presidential Early Career Award for Scientists and Engineers (PECASE) and the David and Lucille Packard Fellowship in Science and Engineering.

































Non-Convex Optimization and Structured Signal Recovery 




Date: November 1, 2018					





Time: 2:00 pm					





Room: DBH 4011					





Speaker: Babak Hassibi 					





				 (Caltech)					











































Abstract: In the past couple of decades, non-smooth convex optimization has emerged as a powerful tool for the recovery of structured signals (sparse, low rank, finite constellation, etc.) from possibly noisy measurements in a variety of applications in statistics, signal processing and machine learning. While the algorithms (basis pursuit, LASSO, etc.) are often fairly well established, rigorous frameworks for the exact analysis of the performance of such methods are only just emerging. The talk will introduce and describe a fairly general theory for how to determine the performance (minimum number of measurements, mean-square-error, probability-of-error, etc.) of such methods for various measurement ensembles (Gaussian, Haar, etc.). The framework enables one to assess the performance of these methods before actual implementation and allows one to optimally choose parameters such as regularizer coefficients, number of measurements, etc. The theory subsumes earlier results as special cases. It builds on an inconspicuous 1962 lemma of Slepian (for comparing Gaussian processes), as well as on a non-trivial generalization due to Gordon in 1988, and produces concepts from convex geometry (such as Gaussian widths and Moreau envelopes) in a very natural way. The talk will also consider extensions to certain non-Gaussian settings and their applications in massive MIMO, one-bit compressed sensing, graphical LASSO, and phase retrieval.






Bio: Babak Hassibi is the inaugural Mose and Lillian S. Bohn Professor of Electrical Engineering at the California Institute of Technology, where he has been since 2001, From 2011 to 2016 he was the Gordon M Binder/Amgen Professor of Electrical Engineering and during 2008-2015 he was Executive Officer of Electrical Engineering, as well as Associate Director of Information Science and Technology. Prior to Caltech, he was a Member of the Technical Staff in the Mathematical Sciences Research Center at Bell Laboratories, Murray Hill, NJ. He obtained his PhD degree from Stanford University in 1996 and his BS degree from the University of Tehran in 1989. His research interests span various aspects of information theory, communications, signal processing, control and machine learning. He is an ISI highly cited author in Computer Science and, among other awards, is the recipient of the US Presidential Early Career Award for Scientists and Engineers (PECASE) and the David and Lucille Packard Fellowship in Science and Engineering.























Non-Convex Optimization and Structured Signal Recovery 




Date: November 1, 2018					





Time: 2:00 pm					





Room: DBH 4011					





Speaker: Babak Hassibi 					





				 (Caltech)					











































Abstract: In the past couple of decades, non-smooth convex optimization has emerged as a powerful tool for the recovery of structured signals (sparse, low rank, finite constellation, etc.) from possibly noisy measurements in a variety of applications in statistics, signal processing and machine learning. While the algorithms (basis pursuit, LASSO, etc.) are often fairly well established, rigorous frameworks for the exact analysis of the performance of such methods are only just emerging. The talk will introduce and describe a fairly general theory for how to determine the performance (minimum number of measurements, mean-square-error, probability-of-error, etc.) of such methods for various measurement ensembles (Gaussian, Haar, etc.). The framework enables one to assess the performance of these methods before actual implementation and allows one to optimally choose parameters such as regularizer coefficients, number of measurements, etc. The theory subsumes earlier results as special cases. It builds on an inconspicuous 1962 lemma of Slepian (for comparing Gaussian processes), as well as on a non-trivial generalization due to Gordon in 1988, and produces concepts from convex geometry (such as Gaussian widths and Moreau envelopes) in a very natural way. The talk will also consider extensions to certain non-Gaussian settings and their applications in massive MIMO, one-bit compressed sensing, graphical LASSO, and phase retrieval.






Bio: Babak Hassibi is the inaugural Mose and Lillian S. Bohn Professor of Electrical Engineering at the California Institute of Technology, where he has been since 2001, From 2011 to 2016 he was the Gordon M Binder/Amgen Professor of Electrical Engineering and during 2008-2015 he was Executive Officer of Electrical Engineering, as well as Associate Director of Information Science and Technology. Prior to Caltech, he was a Member of the Technical Staff in the Mathematical Sciences Research Center at Bell Laboratories, Murray Hill, NJ. He obtained his PhD degree from Stanford University in 1996 and his BS degree from the University of Tehran in 1989. His research interests span various aspects of information theory, communications, signal processing, control and machine learning. He is an ISI highly cited author in Computer Science and, among other awards, is the recipient of the US Presidential Early Career Award for Scientists and Engineers (PECASE) and the David and Lucille Packard Fellowship in Science and Engineering.





















Non-Convex Optimization and Structured Signal Recovery 




Date: November 1, 2018					





Time: 2:00 pm					





Room: DBH 4011					





Speaker: Babak Hassibi 					





				 (Caltech)					











































Abstract: In the past couple of decades, non-smooth convex optimization has emerged as a powerful tool for the recovery of structured signals (sparse, low rank, finite constellation, etc.) from possibly noisy measurements in a variety of applications in statistics, signal processing and machine learning. While the algorithms (basis pursuit, LASSO, etc.) are often fairly well established, rigorous frameworks for the exact analysis of the performance of such methods are only just emerging. The talk will introduce and describe a fairly general theory for how to determine the performance (minimum number of measurements, mean-square-error, probability-of-error, etc.) of such methods for various measurement ensembles (Gaussian, Haar, etc.). The framework enables one to assess the performance of these methods before actual implementation and allows one to optimally choose parameters such as regularizer coefficients, number of measurements, etc. The theory subsumes earlier results as special cases. It builds on an inconspicuous 1962 lemma of Slepian (for comparing Gaussian processes), as well as on a non-trivial generalization due to Gordon in 1988, and produces concepts from convex geometry (such as Gaussian widths and Moreau envelopes) in a very natural way. The talk will also consider extensions to certain non-Gaussian settings and their applications in massive MIMO, one-bit compressed sensing, graphical LASSO, and phase retrieval.






Bio: Babak Hassibi is the inaugural Mose and Lillian S. Bohn Professor of Electrical Engineering at the California Institute of Technology, where he has been since 2001, From 2011 to 2016 he was the Gordon M Binder/Amgen Professor of Electrical Engineering and during 2008-2015 he was Executive Officer of Electrical Engineering, as well as Associate Director of Information Science and Technology. Prior to Caltech, he was a Member of the Technical Staff in the Mathematical Sciences Research Center at Bell Laboratories, Murray Hill, NJ. He obtained his PhD degree from Stanford University in 1996 and his BS degree from the University of Tehran in 1989. His research interests span various aspects of information theory, communications, signal processing, control and machine learning. He is an ISI highly cited author in Computer Science and, among other awards, is the recipient of the US Presidential Early Career Award for Scientists and Engineers (PECASE) and the David and Lucille Packard Fellowship in Science and Engineering.



















Non-Convex Optimization and Structured Signal Recovery 




Date: November 1, 2018					





Time: 2:00 pm					





Room: DBH 4011					





Speaker: Babak Hassibi 					





				 (Caltech)					











































Abstract: In the past couple of decades, non-smooth convex optimization has emerged as a powerful tool for the recovery of structured signals (sparse, low rank, finite constellation, etc.) from possibly noisy measurements in a variety of applications in statistics, signal processing and machine learning. While the algorithms (basis pursuit, LASSO, etc.) are often fairly well established, rigorous frameworks for the exact analysis of the performance of such methods are only just emerging. The talk will introduce and describe a fairly general theory for how to determine the performance (minimum number of measurements, mean-square-error, probability-of-error, etc.) of such methods for various measurement ensembles (Gaussian, Haar, etc.). The framework enables one to assess the performance of these methods before actual implementation and allows one to optimally choose parameters such as regularizer coefficients, number of measurements, etc. The theory subsumes earlier results as special cases. It builds on an inconspicuous 1962 lemma of Slepian (for comparing Gaussian processes), as well as on a non-trivial generalization due to Gordon in 1988, and produces concepts from convex geometry (such as Gaussian widths and Moreau envelopes) in a very natural way. The talk will also consider extensions to certain non-Gaussian settings and their applications in massive MIMO, one-bit compressed sensing, graphical LASSO, and phase retrieval.






Bio: Babak Hassibi is the inaugural Mose and Lillian S. Bohn Professor of Electrical Engineering at the California Institute of Technology, where he has been since 2001, From 2011 to 2016 he was the Gordon M Binder/Amgen Professor of Electrical Engineering and during 2008-2015 he was Executive Officer of Electrical Engineering, as well as Associate Director of Information Science and Technology. Prior to Caltech, he was a Member of the Technical Staff in the Mathematical Sciences Research Center at Bell Laboratories, Murray Hill, NJ. He obtained his PhD degree from Stanford University in 1996 and his BS degree from the University of Tehran in 1989. His research interests span various aspects of information theory, communications, signal processing, control and machine learning. He is an ISI highly cited author in Computer Science and, among other awards, is the recipient of the US Presidential Early Career Award for Scientists and Engineers (PECASE) and the David and Lucille Packard Fellowship in Science and Engineering.
















Non-Convex Optimization and Structured Signal Recovery 




Date: November 1, 2018					





Time: 2:00 pm					





Room: DBH 4011					





Speaker: Babak Hassibi 					





				 (Caltech)					












Non-Convex Optimization and Structured Signal Recovery 




Date: November 1, 2018					





Time: 2:00 pm					





Room: DBH 4011					





Speaker: Babak Hassibi 					





				 (Caltech)					










Non-Convex Optimization and Structured Signal Recovery 




Date: November 1, 2018					





Time: 2:00 pm					





Room: DBH 4011					





Speaker: Babak Hassibi 					





				 (Caltech)					








Non-Convex Optimization and Structured Signal Recovery 




Date: November 1, 2018					





Time: 2:00 pm					





Room: DBH 4011					





Speaker: Babak Hassibi 					





				 (Caltech)					






Non-Convex Optimization and Structured Signal Recovery 




Date: November 1, 2018					





Time: 2:00 pm					





Room: DBH 4011					





Speaker: Babak Hassibi 					





				 (Caltech)					




Non-Convex Optimization and Structured Signal Recovery 

Non-Convex Optimization and Structured Signal Recovery 


Date: November 1, 2018					



Date: November 1, 2018					

Date: November 1, 2018					


Time: 2:00 pm					



Time: 2:00 pm					

Time: 2:00 pm					


Room: DBH 4011					



Room: DBH 4011					

Room: DBH 4011					


Speaker: Babak Hassibi 					



Speaker: Babak Hassibi 					

Speaker: Babak Hassibi 					


				 (Caltech)					



				 (Caltech)					

				 (Caltech)					































































































































Abstract: In the past couple of decades, non-smooth convex optimization has emerged as a powerful tool for the recovery of structured signals (sparse, low rank, finite constellation, etc.) from possibly noisy measurements in a variety of applications in statistics, signal processing and machine learning. While the algorithms (basis pursuit, LASSO, etc.) are often fairly well established, rigorous frameworks for the exact analysis of the performance of such methods are only just emerging. The talk will introduce and describe a fairly general theory for how to determine the performance (minimum number of measurements, mean-square-error, probability-of-error, etc.) of such methods for various measurement ensembles (Gaussian, Haar, etc.). The framework enables one to assess the performance of these methods before actual implementation and allows one to optimally choose parameters such as regularizer coefficients, number of measurements, etc. The theory subsumes earlier results as special cases. It builds on an inconspicuous 1962 lemma of Slepian (for comparing Gaussian processes), as well as on a non-trivial generalization due to Gordon in 1988, and produces concepts from convex geometry (such as Gaussian widths and Moreau envelopes) in a very natural way. The talk will also consider extensions to certain non-Gaussian settings and their applications in massive MIMO, one-bit compressed sensing, graphical LASSO, and phase retrieval.






Bio: Babak Hassibi is the inaugural Mose and Lillian S. Bohn Professor of Electrical Engineering at the California Institute of Technology, where he has been since 2001, From 2011 to 2016 he was the Gordon M Binder/Amgen Professor of Electrical Engineering and during 2008-2015 he was Executive Officer of Electrical Engineering, as well as Associate Director of Information Science and Technology. Prior to Caltech, he was a Member of the Technical Staff in the Mathematical Sciences Research Center at Bell Laboratories, Murray Hill, NJ. He obtained his PhD degree from Stanford University in 1996 and his BS degree from the University of Tehran in 1989. His research interests span various aspects of information theory, communications, signal processing, control and machine learning. He is an ISI highly cited author in Computer Science and, among other awards, is the recipient of the US Presidential Early Career Award for Scientists and Engineers (PECASE) and the David and Lucille Packard Fellowship in Science and Engineering.














Abstract: In the past couple of decades, non-smooth convex optimization has emerged as a powerful tool for the recovery of structured signals (sparse, low rank, finite constellation, etc.) from possibly noisy measurements in a variety of applications in statistics, signal processing and machine learning. While the algorithms (basis pursuit, LASSO, etc.) are often fairly well established, rigorous frameworks for the exact analysis of the performance of such methods are only just emerging. The talk will introduce and describe a fairly general theory for how to determine the performance (minimum number of measurements, mean-square-error, probability-of-error, etc.) of such methods for various measurement ensembles (Gaussian, Haar, etc.). The framework enables one to assess the performance of these methods before actual implementation and allows one to optimally choose parameters such as regularizer coefficients, number of measurements, etc. The theory subsumes earlier results as special cases. It builds on an inconspicuous 1962 lemma of Slepian (for comparing Gaussian processes), as well as on a non-trivial generalization due to Gordon in 1988, and produces concepts from convex geometry (such as Gaussian widths and Moreau envelopes) in a very natural way. The talk will also consider extensions to certain non-Gaussian settings and their applications in massive MIMO, one-bit compressed sensing, graphical LASSO, and phase retrieval.






Bio: Babak Hassibi is the inaugural Mose and Lillian S. Bohn Professor of Electrical Engineering at the California Institute of Technology, where he has been since 2001, From 2011 to 2016 he was the Gordon M Binder/Amgen Professor of Electrical Engineering and during 2008-2015 he was Executive Officer of Electrical Engineering, as well as Associate Director of Information Science and Technology. Prior to Caltech, he was a Member of the Technical Staff in the Mathematical Sciences Research Center at Bell Laboratories, Murray Hill, NJ. He obtained his PhD degree from Stanford University in 1996 and his BS degree from the University of Tehran in 1989. His research interests span various aspects of information theory, communications, signal processing, control and machine learning. He is an ISI highly cited author in Computer Science and, among other awards, is the recipient of the US Presidential Early Career Award for Scientists and Engineers (PECASE) and the David and Lucille Packard Fellowship in Science and Engineering.












Abstract: In the past couple of decades, non-smooth convex optimization has emerged as a powerful tool for the recovery of structured signals (sparse, low rank, finite constellation, etc.) from possibly noisy measurements in a variety of applications in statistics, signal processing and machine learning. While the algorithms (basis pursuit, LASSO, etc.) are often fairly well established, rigorous frameworks for the exact analysis of the performance of such methods are only just emerging. The talk will introduce and describe a fairly general theory for how to determine the performance (minimum number of measurements, mean-square-error, probability-of-error, etc.) of such methods for various measurement ensembles (Gaussian, Haar, etc.). The framework enables one to assess the performance of these methods before actual implementation and allows one to optimally choose parameters such as regularizer coefficients, number of measurements, etc. The theory subsumes earlier results as special cases. It builds on an inconspicuous 1962 lemma of Slepian (for comparing Gaussian processes), as well as on a non-trivial generalization due to Gordon in 1988, and produces concepts from convex geometry (such as Gaussian widths and Moreau envelopes) in a very natural way. The talk will also consider extensions to certain non-Gaussian settings and their applications in massive MIMO, one-bit compressed sensing, graphical LASSO, and phase retrieval.






Bio: Babak Hassibi is the inaugural Mose and Lillian S. Bohn Professor of Electrical Engineering at the California Institute of Technology, where he has been since 2001, From 2011 to 2016 he was the Gordon M Binder/Amgen Professor of Electrical Engineering and during 2008-2015 he was Executive Officer of Electrical Engineering, as well as Associate Director of Information Science and Technology. Prior to Caltech, he was a Member of the Technical Staff in the Mathematical Sciences Research Center at Bell Laboratories, Murray Hill, NJ. He obtained his PhD degree from Stanford University in 1996 and his BS degree from the University of Tehran in 1989. His research interests span various aspects of information theory, communications, signal processing, control and machine learning. He is an ISI highly cited author in Computer Science and, among other awards, is the recipient of the US Presidential Early Career Award for Scientists and Engineers (PECASE) and the David and Lucille Packard Fellowship in Science and Engineering.










Abstract: In the past couple of decades, non-smooth convex optimization has emerged as a powerful tool for the recovery of structured signals (sparse, low rank, finite constellation, etc.) from possibly noisy measurements in a variety of applications in statistics, signal processing and machine learning. While the algorithms (basis pursuit, LASSO, etc.) are often fairly well established, rigorous frameworks for the exact analysis of the performance of such methods are only just emerging. The talk will introduce and describe a fairly general theory for how to determine the performance (minimum number of measurements, mean-square-error, probability-of-error, etc.) of such methods for various measurement ensembles (Gaussian, Haar, etc.). The framework enables one to assess the performance of these methods before actual implementation and allows one to optimally choose parameters such as regularizer coefficients, number of measurements, etc. The theory subsumes earlier results as special cases. It builds on an inconspicuous 1962 lemma of Slepian (for comparing Gaussian processes), as well as on a non-trivial generalization due to Gordon in 1988, and produces concepts from convex geometry (such as Gaussian widths and Moreau envelopes) in a very natural way. The talk will also consider extensions to certain non-Gaussian settings and their applications in massive MIMO, one-bit compressed sensing, graphical LASSO, and phase retrieval.






Bio: Babak Hassibi is the inaugural Mose and Lillian S. Bohn Professor of Electrical Engineering at the California Institute of Technology, where he has been since 2001, From 2011 to 2016 he was the Gordon M Binder/Amgen Professor of Electrical Engineering and during 2008-2015 he was Executive Officer of Electrical Engineering, as well as Associate Director of Information Science and Technology. Prior to Caltech, he was a Member of the Technical Staff in the Mathematical Sciences Research Center at Bell Laboratories, Murray Hill, NJ. He obtained his PhD degree from Stanford University in 1996 and his BS degree from the University of Tehran in 1989. His research interests span various aspects of information theory, communications, signal processing, control and machine learning. He is an ISI highly cited author in Computer Science and, among other awards, is the recipient of the US Presidential Early Career Award for Scientists and Engineers (PECASE) and the David and Lucille Packard Fellowship in Science and Engineering.








Abstract: In the past couple of decades, non-smooth convex optimization has emerged as a powerful tool for the recovery of structured signals (sparse, low rank, finite constellation, etc.) from possibly noisy measurements in a variety of applications in statistics, signal processing and machine learning. While the algorithms (basis pursuit, LASSO, etc.) are often fairly well established, rigorous frameworks for the exact analysis of the performance of such methods are only just emerging. The talk will introduce and describe a fairly general theory for how to determine the performance (minimum number of measurements, mean-square-error, probability-of-error, etc.) of such methods for various measurement ensembles (Gaussian, Haar, etc.). The framework enables one to assess the performance of these methods before actual implementation and allows one to optimally choose parameters such as regularizer coefficients, number of measurements, etc. The theory subsumes earlier results as special cases. It builds on an inconspicuous 1962 lemma of Slepian (for comparing Gaussian processes), as well as on a non-trivial generalization due to Gordon in 1988, and produces concepts from convex geometry (such as Gaussian widths and Moreau envelopes) in a very natural way. The talk will also consider extensions to certain non-Gaussian settings and their applications in massive MIMO, one-bit compressed sensing, graphical LASSO, and phase retrieval.






Bio: Babak Hassibi is the inaugural Mose and Lillian S. Bohn Professor of Electrical Engineering at the California Institute of Technology, where he has been since 2001, From 2011 to 2016 he was the Gordon M Binder/Amgen Professor of Electrical Engineering and during 2008-2015 he was Executive Officer of Electrical Engineering, as well as Associate Director of Information Science and Technology. Prior to Caltech, he was a Member of the Technical Staff in the Mathematical Sciences Research Center at Bell Laboratories, Murray Hill, NJ. He obtained his PhD degree from Stanford University in 1996 and his BS degree from the University of Tehran in 1989. His research interests span various aspects of information theory, communications, signal processing, control and machine learning. He is an ISI highly cited author in Computer Science and, among other awards, is the recipient of the US Presidential Early Career Award for Scientists and Engineers (PECASE) and the David and Lucille Packard Fellowship in Science and Engineering.






Abstract: In the past couple of decades, non-smooth convex optimization has emerged as a powerful tool for the recovery of structured signals (sparse, low rank, finite constellation, etc.) from possibly noisy measurements in a variety of applications in statistics, signal processing and machine learning. While the algorithms (basis pursuit, LASSO, etc.) are often fairly well established, rigorous frameworks for the exact analysis of the performance of such methods are only just emerging. The talk will introduce and describe a fairly general theory for how to determine the performance (minimum number of measurements, mean-square-error, probability-of-error, etc.) of such methods for various measurement ensembles (Gaussian, Haar, etc.). The framework enables one to assess the performance of these methods before actual implementation and allows one to optimally choose parameters such as regularizer coefficients, number of measurements, etc. The theory subsumes earlier results as special cases. It builds on an inconspicuous 1962 lemma of Slepian (for comparing Gaussian processes), as well as on a non-trivial generalization due to Gordon in 1988, and produces concepts from convex geometry (such as Gaussian widths and Moreau envelopes) in a very natural way. The talk will also consider extensions to certain non-Gaussian settings and their applications in massive MIMO, one-bit compressed sensing, graphical LASSO, and phase retrieval.




Abstract: In the past couple of decades, non-smooth convex optimization has emerged as a powerful tool for the recovery of structured signals (sparse, low rank, finite constellation, etc.) from possibly noisy measurements in a variety of applications in statistics, signal processing and machine learning. While the algorithms (basis pursuit, LASSO, etc.) are often fairly well established, rigorous frameworks for the exact analysis of the performance of such methods are only just emerging. The talk will introduce and describe a fairly general theory for how to determine the performance (minimum number of measurements, mean-square-error, probability-of-error, etc.) of such methods for various measurement ensembles (Gaussian, Haar, etc.). The framework enables one to assess the performance of these methods before actual implementation and allows one to optimally choose parameters such as regularizer coefficients, number of measurements, etc. The theory subsumes earlier results as special cases. It builds on an inconspicuous 1962 lemma of Slepian (for comparing Gaussian processes), as well as on a non-trivial generalization due to Gordon in 1988, and produces concepts from convex geometry (such as Gaussian widths and Moreau envelopes) in a very natural way. The talk will also consider extensions to certain non-Gaussian settings and their applications in massive MIMO, one-bit compressed sensing, graphical LASSO, and phase retrieval.


Abstract: In the past couple of decades, non-smooth convex optimization has emerged as a powerful tool for the recovery of structured signals (sparse, low rank, finite constellation, etc.) from possibly noisy measurements in a variety of applications in statistics, signal processing and machine learning. While the algorithms (basis pursuit, LASSO, etc.) are often fairly well established, rigorous frameworks for the exact analysis of the performance of such methods are only just emerging. The talk will introduce and describe a fairly general theory for how to determine the performance (minimum number of measurements, mean-square-error, probability-of-error, etc.) of such methods for various measurement ensembles (Gaussian, Haar, etc.). The framework enables one to assess the performance of these methods before actual implementation and allows one to optimally choose parameters such as regularizer coefficients, number of measurements, etc. The theory subsumes earlier results as special cases. It builds on an inconspicuous 1962 lemma of Slepian (for comparing Gaussian processes), as well as on a non-trivial generalization due to Gordon in 1988, and produces concepts from convex geometry (such as Gaussian widths and Moreau envelopes) in a very natural way. The talk will also consider extensions to certain non-Gaussian settings and their applications in massive MIMO, one-bit compressed sensing, graphical LASSO, and phase retrieval.
In the past couple of decades, non-smooth convex optimization has emerged as a powerful tool for the recovery of structured signals (sparse, low rank, finite constellation, etc.) from possibly noisy measurements in a variety of applications in statistics, signal processing and machine learning. While the algorithms (basis pursuit, LASSO, etc.) are often fairly well established, rigorous frameworks for the exact analysis of the performance of such methods are only just emerging. The talk will introduce and describe a fairly general theory for how to determine the performance (minimum number of measurements, mean-square-error, probability-of-error, etc.) of such methods for various measurement ensembles (Gaussian, Haar, etc.). The framework enables one to assess the performance of these methods before actual implementation and allows one to optimally choose parameters such as regularizer coefficients, number of measurements, etc. The theory subsumes earlier results as special cases. It builds on an inconspicuous 1962 lemma of Slepian (for comparing Gaussian processes), as well as on a non-trivial generalization due to Gordon in 1988, and produces concepts from convex geometry (such as Gaussian widths and Moreau envelopes) in a very natural way. The talk will also consider extensions to certain non-Gaussian settings and their applications in massive MIMO, one-bit compressed sensing, graphical LASSO, and phase retrieval.


Bio: Babak Hassibi is the inaugural Mose and Lillian S. Bohn Professor of Electrical Engineering at the California Institute of Technology, where he has been since 2001, From 2011 to 2016 he was the Gordon M Binder/Amgen Professor of Electrical Engineering and during 2008-2015 he was Executive Officer of Electrical Engineering, as well as Associate Director of Information Science and Technology. Prior to Caltech, he was a Member of the Technical Staff in the Mathematical Sciences Research Center at Bell Laboratories, Murray Hill, NJ. He obtained his PhD degree from Stanford University in 1996 and his BS degree from the University of Tehran in 1989. His research interests span various aspects of information theory, communications, signal processing, control and machine learning. He is an ISI highly cited author in Computer Science and, among other awards, is the recipient of the US Presidential Early Career Award for Scientists and Engineers (PECASE) and the David and Lucille Packard Fellowship in Science and Engineering.




Bio: Babak Hassibi is the inaugural Mose and Lillian S. Bohn Professor of Electrical Engineering at the California Institute of Technology, where he has been since 2001, From 2011 to 2016 he was the Gordon M Binder/Amgen Professor of Electrical Engineering and during 2008-2015 he was Executive Officer of Electrical Engineering, as well as Associate Director of Information Science and Technology. Prior to Caltech, he was a Member of the Technical Staff in the Mathematical Sciences Research Center at Bell Laboratories, Murray Hill, NJ. He obtained his PhD degree from Stanford University in 1996 and his BS degree from the University of Tehran in 1989. His research interests span various aspects of information theory, communications, signal processing, control and machine learning. He is an ISI highly cited author in Computer Science and, among other awards, is the recipient of the US Presidential Early Career Award for Scientists and Engineers (PECASE) and the David and Lucille Packard Fellowship in Science and Engineering.


Bio: Babak Hassibi is the inaugural Mose and Lillian S. Bohn Professor of Electrical Engineering at the California Institute of Technology, where he has been since 2001, From 2011 to 2016 he was the Gordon M Binder/Amgen Professor of Electrical Engineering and during 2008-2015 he was Executive Officer of Electrical Engineering, as well as Associate Director of Information Science and Technology. Prior to Caltech, he was a Member of the Technical Staff in the Mathematical Sciences Research Center at Bell Laboratories, Murray Hill, NJ. He obtained his PhD degree from Stanford University in 1996 and his BS degree from the University of Tehran in 1989. His research interests span various aspects of information theory, communications, signal processing, control and machine learning. He is an ISI highly cited author in Computer Science and, among other awards, is the recipient of the US Presidential Early Career Award for Scientists and Engineers (PECASE) and the David and Lucille Packard Fellowship in Science and Engineering.
Babak Hassibi is the inaugural Mose and Lillian S. Bohn Professor of Electrical Engineering at the California Institute of Technology, where he has been since 2001, From 2011 to 2016 he was the Gordon M Binder/Amgen Professor of Electrical Engineering and during 2008-2015 he was Executive Officer of Electrical Engineering, as well as Associate Director of Information Science and Technology. Prior to Caltech, he was a Member of the Technical Staff in the Mathematical Sciences Research Center at Bell Laboratories, Murray Hill, NJ. He obtained his PhD degree from Stanford University in 1996 and his BS degree from the University of Tehran in 1989. His research interests span various aspects of information theory, communications, signal processing, control and machine learning. He is an ISI highly cited author in Computer Science and, among other awards, is the recipient of the US Presidential Early Career Award for Scientists and Engineers (PECASE) and the David and Lucille Packard Fellowship in Science and Engineering.












ACO Center @ UCI • Privacy Policy • © 2022 UC Regents 






ACO Center @ UCI • Privacy Policy • © 2022 UC Regents 




ACO Center @ UCI • Privacy Policy • © 2022 UC Regents 


ACO Center @ UCI • Privacy Policy • © 2022 UC Regents 

Close Menu

Close Menu








Open toolbar

 

Open toolbar

Accessibility Tools



Increase Text 



Decrease Text 



Grayscale 



High Contrast 



Negative Contrast 



Light Background 



Links Underline 



Readable Font 




Reset





Accessibility Tools



Increase Text 



Decrease Text 



Grayscale 



High Contrast 



Negative Contrast 



Light Background 



Links Underline 



Readable Font 




Reset



Accessibility Tools

Increase Text 
Increase Text

Decrease Text 
Decrease Text

Grayscale 
Grayscale

High Contrast 
High Contrast

Negative Contrast 
Negative Contrast

Light Background 
Light Background

Links Underline 
Links Underline

Readable Font 
Readable Font


Reset

Reset