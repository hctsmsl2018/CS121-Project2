












ACO Center @ UCI  




Algorithms, Combinatorics and Optimization 













 Search





















Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 

 Menu


Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 

















Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 

 Menu


Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 














Computational phase transition and MCMC algorithms
Home>Seminars>Computational phase transition and MCMC algorithms















Computational phase transition and MCMC algorithms 




Date: March 31, 2022					





Time: 4:00 pm					





Room: DBH 4011					





Speaker: Eric Vigoda 					





				 (UC Santa Barbara)					











































Abstract: This talk will highlight recent results establishing a beautiful computational phase transition for approximate counting/sampling in (binary) undirected graphical models (such as the Ising model).  The computational problem is to sample from the equilibrium distribution of the model or equivalently approximate the corresponding normalizing factor known as the partition function.  We show that when correlations die off on the infinite D-regular tree then the Gibbs sampler has optimal mixing time of O(nlogn) on any graph of maximum degree D, whereas when the correlations persist (in the limit) then the sampling/counting problem are NP-hard to approximate.  The Gibbs sampler is a simple Markov Chain Monte Carlo (MCMC) algorithm.  Key to these mixing results are a new technique known as spectral independence which considers the pairwise influence of vertices.   We show that spectral independence implies an optimal convergence rate for a variety of MCMC algorithms.






Bio: Eric Vigoda is a Professor of Computer Science at the University of California, Santa Barbara since 2021. Previously, he was on the faculty at Georgia Tech and the University of Chicago. Vigoda completed his PhD in Computer Science from UC Berkeley in 1999.  With Mark Jerrum and Alistair Sinclair, they won a Fulkerson prize for their work on approximating the permanent of a non-negative matrix.  He is a Fellow of the American Mathematical Society.





























ACO Center @ UCI • Privacy Policy • © 2022 UC Regents 

















ACO Center @ UCI  




Algorithms, Combinatorics and Optimization 













 Search





















Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 

 Menu


Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 

















Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 

 Menu


Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 














Computational phase transition and MCMC algorithms
Home>Seminars>Computational phase transition and MCMC algorithms















Computational phase transition and MCMC algorithms 




Date: March 31, 2022					





Time: 4:00 pm					





Room: DBH 4011					





Speaker: Eric Vigoda 					





				 (UC Santa Barbara)					











































Abstract: This talk will highlight recent results establishing a beautiful computational phase transition for approximate counting/sampling in (binary) undirected graphical models (such as the Ising model).  The computational problem is to sample from the equilibrium distribution of the model or equivalently approximate the corresponding normalizing factor known as the partition function.  We show that when correlations die off on the infinite D-regular tree then the Gibbs sampler has optimal mixing time of O(nlogn) on any graph of maximum degree D, whereas when the correlations persist (in the limit) then the sampling/counting problem are NP-hard to approximate.  The Gibbs sampler is a simple Markov Chain Monte Carlo (MCMC) algorithm.  Key to these mixing results are a new technique known as spectral independence which considers the pairwise influence of vertices.   We show that spectral independence implies an optimal convergence rate for a variety of MCMC algorithms.






Bio: Eric Vigoda is a Professor of Computer Science at the University of California, Santa Barbara since 2021. Previously, he was on the faculty at Georgia Tech and the University of Chicago. Vigoda completed his PhD in Computer Science from UC Berkeley in 1999.  With Mark Jerrum and Alistair Sinclair, they won a Fulkerson prize for their work on approximating the permanent of a non-negative matrix.  He is a Fellow of the American Mathematical Society.





























ACO Center @ UCI • Privacy Policy • © 2022 UC Regents 














ACO Center @ UCI  




Algorithms, Combinatorics and Optimization 













 Search





















Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 

 Menu


Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 

















Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 

 Menu


Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 


















ACO Center @ UCI  




Algorithms, Combinatorics and Optimization 













 Search





















Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 

 Menu


Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 

















Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 

 Menu


Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 















ACO Center @ UCI  




Algorithms, Combinatorics and Optimization 













 Search
















ACO Center @ UCI  




Algorithms, Combinatorics and Optimization 













 Search














ACO Center @ UCI  




Algorithms, Combinatorics and Optimization 








ACO Center @ UCI  




Algorithms, Combinatorics and Optimization 






ACO Center @ UCI  




Algorithms, Combinatorics and Optimization 




ACO Center @ UCI  

ACO Center @ UCI  


Algorithms, Combinatorics and Optimization 



Algorithms, Combinatorics and Optimization 

Algorithms, Combinatorics and Optimization Algorithms, Combinatorics and Optimization







 Search















 Search













 Search











 Search









 Search






 Search



 Search
Search







Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 

 Menu


Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 













Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 

 Menu


Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 











Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 

 Menu


Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 









Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 

 Menu


Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 







Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 

 Menu


Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 





Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 

 Menu


Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 



Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 

 Menu


Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 
HomePeopleSeminar SeriesSynergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation

ICSMathBusiness SchoolIMBSEECSCenter for Algorithms and Theory of ComputationNewsContact
 Menu
MenuHomePeopleSeminar SeriesSynergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation

ICSMathBusiness SchoolIMBSEECSCenter for Algorithms and Theory of ComputationNewsContact







Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 

 Menu


Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 













Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 

 Menu


Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 











Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 

 Menu


Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 









Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 

 Menu


Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 







Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 

 Menu


Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 





Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 

 Menu


Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 



Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 

 Menu


Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 
HomePeopleSeminar SeriesSynergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation

ICSMathBusiness SchoolIMBSEECSCenter for Algorithms and Theory of ComputationNewsContact
 Menu
MenuHomePeopleSeminar SeriesSynergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation

ICSMathBusiness SchoolIMBSEECSCenter for Algorithms and Theory of ComputationNewsContact
Computational phase transition and MCMC algorithms
Home>Seminars>Computational phase transition and MCMC algorithms
Home>HomeHome>Seminars>Seminars>Computational phase transition and MCMC algorithmsComputational phase transition and MCMC algorithms












Computational phase transition and MCMC algorithms 




Date: March 31, 2022					





Time: 4:00 pm					





Room: DBH 4011					





Speaker: Eric Vigoda 					





				 (UC Santa Barbara)					











































Abstract: This talk will highlight recent results establishing a beautiful computational phase transition for approximate counting/sampling in (binary) undirected graphical models (such as the Ising model).  The computational problem is to sample from the equilibrium distribution of the model or equivalently approximate the corresponding normalizing factor known as the partition function.  We show that when correlations die off on the infinite D-regular tree then the Gibbs sampler has optimal mixing time of O(nlogn) on any graph of maximum degree D, whereas when the correlations persist (in the limit) then the sampling/counting problem are NP-hard to approximate.  The Gibbs sampler is a simple Markov Chain Monte Carlo (MCMC) algorithm.  Key to these mixing results are a new technique known as spectral independence which considers the pairwise influence of vertices.   We show that spectral independence implies an optimal convergence rate for a variety of MCMC algorithms.






Bio: Eric Vigoda is a Professor of Computer Science at the University of California, Santa Barbara since 2021. Previously, he was on the faculty at Georgia Tech and the University of Chicago. Vigoda completed his PhD in Computer Science from UC Berkeley in 1999.  With Mark Jerrum and Alistair Sinclair, they won a Fulkerson prize for their work on approximating the permanent of a non-negative matrix.  He is a Fellow of the American Mathematical Society.

































Computational phase transition and MCMC algorithms 




Date: March 31, 2022					





Time: 4:00 pm					





Room: DBH 4011					





Speaker: Eric Vigoda 					





				 (UC Santa Barbara)					











































Abstract: This talk will highlight recent results establishing a beautiful computational phase transition for approximate counting/sampling in (binary) undirected graphical models (such as the Ising model).  The computational problem is to sample from the equilibrium distribution of the model or equivalently approximate the corresponding normalizing factor known as the partition function.  We show that when correlations die off on the infinite D-regular tree then the Gibbs sampler has optimal mixing time of O(nlogn) on any graph of maximum degree D, whereas when the correlations persist (in the limit) then the sampling/counting problem are NP-hard to approximate.  The Gibbs sampler is a simple Markov Chain Monte Carlo (MCMC) algorithm.  Key to these mixing results are a new technique known as spectral independence which considers the pairwise influence of vertices.   We show that spectral independence implies an optimal convergence rate for a variety of MCMC algorithms.






Bio: Eric Vigoda is a Professor of Computer Science at the University of California, Santa Barbara since 2021. Previously, he was on the faculty at Georgia Tech and the University of Chicago. Vigoda completed his PhD in Computer Science from UC Berkeley in 1999.  With Mark Jerrum and Alistair Sinclair, they won a Fulkerson prize for their work on approximating the permanent of a non-negative matrix.  He is a Fellow of the American Mathematical Society.























Computational phase transition and MCMC algorithms 




Date: March 31, 2022					





Time: 4:00 pm					





Room: DBH 4011					





Speaker: Eric Vigoda 					





				 (UC Santa Barbara)					











































Abstract: This talk will highlight recent results establishing a beautiful computational phase transition for approximate counting/sampling in (binary) undirected graphical models (such as the Ising model).  The computational problem is to sample from the equilibrium distribution of the model or equivalently approximate the corresponding normalizing factor known as the partition function.  We show that when correlations die off on the infinite D-regular tree then the Gibbs sampler has optimal mixing time of O(nlogn) on any graph of maximum degree D, whereas when the correlations persist (in the limit) then the sampling/counting problem are NP-hard to approximate.  The Gibbs sampler is a simple Markov Chain Monte Carlo (MCMC) algorithm.  Key to these mixing results are a new technique known as spectral independence which considers the pairwise influence of vertices.   We show that spectral independence implies an optimal convergence rate for a variety of MCMC algorithms.






Bio: Eric Vigoda is a Professor of Computer Science at the University of California, Santa Barbara since 2021. Previously, he was on the faculty at Georgia Tech and the University of Chicago. Vigoda completed his PhD in Computer Science from UC Berkeley in 1999.  With Mark Jerrum and Alistair Sinclair, they won a Fulkerson prize for their work on approximating the permanent of a non-negative matrix.  He is a Fellow of the American Mathematical Society.





















Computational phase transition and MCMC algorithms 




Date: March 31, 2022					





Time: 4:00 pm					





Room: DBH 4011					





Speaker: Eric Vigoda 					





				 (UC Santa Barbara)					











































Abstract: This talk will highlight recent results establishing a beautiful computational phase transition for approximate counting/sampling in (binary) undirected graphical models (such as the Ising model).  The computational problem is to sample from the equilibrium distribution of the model or equivalently approximate the corresponding normalizing factor known as the partition function.  We show that when correlations die off on the infinite D-regular tree then the Gibbs sampler has optimal mixing time of O(nlogn) on any graph of maximum degree D, whereas when the correlations persist (in the limit) then the sampling/counting problem are NP-hard to approximate.  The Gibbs sampler is a simple Markov Chain Monte Carlo (MCMC) algorithm.  Key to these mixing results are a new technique known as spectral independence which considers the pairwise influence of vertices.   We show that spectral independence implies an optimal convergence rate for a variety of MCMC algorithms.






Bio: Eric Vigoda is a Professor of Computer Science at the University of California, Santa Barbara since 2021. Previously, he was on the faculty at Georgia Tech and the University of Chicago. Vigoda completed his PhD in Computer Science from UC Berkeley in 1999.  With Mark Jerrum and Alistair Sinclair, they won a Fulkerson prize for their work on approximating the permanent of a non-negative matrix.  He is a Fellow of the American Mathematical Society.



















Computational phase transition and MCMC algorithms 




Date: March 31, 2022					





Time: 4:00 pm					





Room: DBH 4011					





Speaker: Eric Vigoda 					





				 (UC Santa Barbara)					











































Abstract: This talk will highlight recent results establishing a beautiful computational phase transition for approximate counting/sampling in (binary) undirected graphical models (such as the Ising model).  The computational problem is to sample from the equilibrium distribution of the model or equivalently approximate the corresponding normalizing factor known as the partition function.  We show that when correlations die off on the infinite D-regular tree then the Gibbs sampler has optimal mixing time of O(nlogn) on any graph of maximum degree D, whereas when the correlations persist (in the limit) then the sampling/counting problem are NP-hard to approximate.  The Gibbs sampler is a simple Markov Chain Monte Carlo (MCMC) algorithm.  Key to these mixing results are a new technique known as spectral independence which considers the pairwise influence of vertices.   We show that spectral independence implies an optimal convergence rate for a variety of MCMC algorithms.






Bio: Eric Vigoda is a Professor of Computer Science at the University of California, Santa Barbara since 2021. Previously, he was on the faculty at Georgia Tech and the University of Chicago. Vigoda completed his PhD in Computer Science from UC Berkeley in 1999.  With Mark Jerrum and Alistair Sinclair, they won a Fulkerson prize for their work on approximating the permanent of a non-negative matrix.  He is a Fellow of the American Mathematical Society.
















Computational phase transition and MCMC algorithms 




Date: March 31, 2022					





Time: 4:00 pm					





Room: DBH 4011					





Speaker: Eric Vigoda 					





				 (UC Santa Barbara)					












Computational phase transition and MCMC algorithms 




Date: March 31, 2022					





Time: 4:00 pm					





Room: DBH 4011					





Speaker: Eric Vigoda 					





				 (UC Santa Barbara)					










Computational phase transition and MCMC algorithms 




Date: March 31, 2022					





Time: 4:00 pm					





Room: DBH 4011					





Speaker: Eric Vigoda 					





				 (UC Santa Barbara)					








Computational phase transition and MCMC algorithms 




Date: March 31, 2022					





Time: 4:00 pm					





Room: DBH 4011					





Speaker: Eric Vigoda 					





				 (UC Santa Barbara)					






Computational phase transition and MCMC algorithms 




Date: March 31, 2022					





Time: 4:00 pm					





Room: DBH 4011					





Speaker: Eric Vigoda 					





				 (UC Santa Barbara)					




Computational phase transition and MCMC algorithms 

Computational phase transition and MCMC algorithms 


Date: March 31, 2022					



Date: March 31, 2022					

Date: March 31, 2022					


Time: 4:00 pm					



Time: 4:00 pm					

Time: 4:00 pm					


Room: DBH 4011					



Room: DBH 4011					

Room: DBH 4011					


Speaker: Eric Vigoda 					



Speaker: Eric Vigoda 					

Speaker: Eric Vigoda 					


				 (UC Santa Barbara)					



				 (UC Santa Barbara)					

				 (UC Santa Barbara)					































































































































Abstract: This talk will highlight recent results establishing a beautiful computational phase transition for approximate counting/sampling in (binary) undirected graphical models (such as the Ising model).  The computational problem is to sample from the equilibrium distribution of the model or equivalently approximate the corresponding normalizing factor known as the partition function.  We show that when correlations die off on the infinite D-regular tree then the Gibbs sampler has optimal mixing time of O(nlogn) on any graph of maximum degree D, whereas when the correlations persist (in the limit) then the sampling/counting problem are NP-hard to approximate.  The Gibbs sampler is a simple Markov Chain Monte Carlo (MCMC) algorithm.  Key to these mixing results are a new technique known as spectral independence which considers the pairwise influence of vertices.   We show that spectral independence implies an optimal convergence rate for a variety of MCMC algorithms.






Bio: Eric Vigoda is a Professor of Computer Science at the University of California, Santa Barbara since 2021. Previously, he was on the faculty at Georgia Tech and the University of Chicago. Vigoda completed his PhD in Computer Science from UC Berkeley in 1999.  With Mark Jerrum and Alistair Sinclair, they won a Fulkerson prize for their work on approximating the permanent of a non-negative matrix.  He is a Fellow of the American Mathematical Society.














Abstract: This talk will highlight recent results establishing a beautiful computational phase transition for approximate counting/sampling in (binary) undirected graphical models (such as the Ising model).  The computational problem is to sample from the equilibrium distribution of the model or equivalently approximate the corresponding normalizing factor known as the partition function.  We show that when correlations die off on the infinite D-regular tree then the Gibbs sampler has optimal mixing time of O(nlogn) on any graph of maximum degree D, whereas when the correlations persist (in the limit) then the sampling/counting problem are NP-hard to approximate.  The Gibbs sampler is a simple Markov Chain Monte Carlo (MCMC) algorithm.  Key to these mixing results are a new technique known as spectral independence which considers the pairwise influence of vertices.   We show that spectral independence implies an optimal convergence rate for a variety of MCMC algorithms.






Bio: Eric Vigoda is a Professor of Computer Science at the University of California, Santa Barbara since 2021. Previously, he was on the faculty at Georgia Tech and the University of Chicago. Vigoda completed his PhD in Computer Science from UC Berkeley in 1999.  With Mark Jerrum and Alistair Sinclair, they won a Fulkerson prize for their work on approximating the permanent of a non-negative matrix.  He is a Fellow of the American Mathematical Society.












Abstract: This talk will highlight recent results establishing a beautiful computational phase transition for approximate counting/sampling in (binary) undirected graphical models (such as the Ising model).  The computational problem is to sample from the equilibrium distribution of the model or equivalently approximate the corresponding normalizing factor known as the partition function.  We show that when correlations die off on the infinite D-regular tree then the Gibbs sampler has optimal mixing time of O(nlogn) on any graph of maximum degree D, whereas when the correlations persist (in the limit) then the sampling/counting problem are NP-hard to approximate.  The Gibbs sampler is a simple Markov Chain Monte Carlo (MCMC) algorithm.  Key to these mixing results are a new technique known as spectral independence which considers the pairwise influence of vertices.   We show that spectral independence implies an optimal convergence rate for a variety of MCMC algorithms.






Bio: Eric Vigoda is a Professor of Computer Science at the University of California, Santa Barbara since 2021. Previously, he was on the faculty at Georgia Tech and the University of Chicago. Vigoda completed his PhD in Computer Science from UC Berkeley in 1999.  With Mark Jerrum and Alistair Sinclair, they won a Fulkerson prize for their work on approximating the permanent of a non-negative matrix.  He is a Fellow of the American Mathematical Society.










Abstract: This talk will highlight recent results establishing a beautiful computational phase transition for approximate counting/sampling in (binary) undirected graphical models (such as the Ising model).  The computational problem is to sample from the equilibrium distribution of the model or equivalently approximate the corresponding normalizing factor known as the partition function.  We show that when correlations die off on the infinite D-regular tree then the Gibbs sampler has optimal mixing time of O(nlogn) on any graph of maximum degree D, whereas when the correlations persist (in the limit) then the sampling/counting problem are NP-hard to approximate.  The Gibbs sampler is a simple Markov Chain Monte Carlo (MCMC) algorithm.  Key to these mixing results are a new technique known as spectral independence which considers the pairwise influence of vertices.   We show that spectral independence implies an optimal convergence rate for a variety of MCMC algorithms.






Bio: Eric Vigoda is a Professor of Computer Science at the University of California, Santa Barbara since 2021. Previously, he was on the faculty at Georgia Tech and the University of Chicago. Vigoda completed his PhD in Computer Science from UC Berkeley in 1999.  With Mark Jerrum and Alistair Sinclair, they won a Fulkerson prize for their work on approximating the permanent of a non-negative matrix.  He is a Fellow of the American Mathematical Society.








Abstract: This talk will highlight recent results establishing a beautiful computational phase transition for approximate counting/sampling in (binary) undirected graphical models (such as the Ising model).  The computational problem is to sample from the equilibrium distribution of the model or equivalently approximate the corresponding normalizing factor known as the partition function.  We show that when correlations die off on the infinite D-regular tree then the Gibbs sampler has optimal mixing time of O(nlogn) on any graph of maximum degree D, whereas when the correlations persist (in the limit) then the sampling/counting problem are NP-hard to approximate.  The Gibbs sampler is a simple Markov Chain Monte Carlo (MCMC) algorithm.  Key to these mixing results are a new technique known as spectral independence which considers the pairwise influence of vertices.   We show that spectral independence implies an optimal convergence rate for a variety of MCMC algorithms.






Bio: Eric Vigoda is a Professor of Computer Science at the University of California, Santa Barbara since 2021. Previously, he was on the faculty at Georgia Tech and the University of Chicago. Vigoda completed his PhD in Computer Science from UC Berkeley in 1999.  With Mark Jerrum and Alistair Sinclair, they won a Fulkerson prize for their work on approximating the permanent of a non-negative matrix.  He is a Fellow of the American Mathematical Society.






Abstract: This talk will highlight recent results establishing a beautiful computational phase transition for approximate counting/sampling in (binary) undirected graphical models (such as the Ising model).  The computational problem is to sample from the equilibrium distribution of the model or equivalently approximate the corresponding normalizing factor known as the partition function.  We show that when correlations die off on the infinite D-regular tree then the Gibbs sampler has optimal mixing time of O(nlogn) on any graph of maximum degree D, whereas when the correlations persist (in the limit) then the sampling/counting problem are NP-hard to approximate.  The Gibbs sampler is a simple Markov Chain Monte Carlo (MCMC) algorithm.  Key to these mixing results are a new technique known as spectral independence which considers the pairwise influence of vertices.   We show that spectral independence implies an optimal convergence rate for a variety of MCMC algorithms.




Abstract: This talk will highlight recent results establishing a beautiful computational phase transition for approximate counting/sampling in (binary) undirected graphical models (such as the Ising model).  The computational problem is to sample from the equilibrium distribution of the model or equivalently approximate the corresponding normalizing factor known as the partition function.  We show that when correlations die off on the infinite D-regular tree then the Gibbs sampler has optimal mixing time of O(nlogn) on any graph of maximum degree D, whereas when the correlations persist (in the limit) then the sampling/counting problem are NP-hard to approximate.  The Gibbs sampler is a simple Markov Chain Monte Carlo (MCMC) algorithm.  Key to these mixing results are a new technique known as spectral independence which considers the pairwise influence of vertices.   We show that spectral independence implies an optimal convergence rate for a variety of MCMC algorithms.


Abstract: This talk will highlight recent results establishing a beautiful computational phase transition for approximate counting/sampling in (binary) undirected graphical models (such as the Ising model).  The computational problem is to sample from the equilibrium distribution of the model or equivalently approximate the corresponding normalizing factor known as the partition function.  We show that when correlations die off on the infinite D-regular tree then the Gibbs sampler has optimal mixing time of O(nlogn) on any graph of maximum degree D, whereas when the correlations persist (in the limit) then the sampling/counting problem are NP-hard to approximate.  The Gibbs sampler is a simple Markov Chain Monte Carlo (MCMC) algorithm.  Key to these mixing results are a new technique known as spectral independence which considers the pairwise influence of vertices.   We show that spectral independence implies an optimal convergence rate for a variety of MCMC algorithms.
This talk will highlight recent results establishing a beautiful computational phase transition for approximate counting/sampling in (binary) undirected graphical models (such as the Ising model).  The computational problem is to sample from the equilibrium distribution of the model or equivalently approximate the corresponding normalizing factor known as the partition function.  We show that when correlations die off on the infinite D-regular tree then the Gibbs sampler has optimal mixing time of O(nlogn) on any graph of maximum degree D, whereas when the correlations persist (in the limit) then the sampling/counting problem are NP-hard to approximate.  The Gibbs sampler is a simple Markov Chain Monte Carlo (MCMC) algorithm.  Key to these mixing results are a new technique known as spectral independence which considers the pairwise influence of vertices.   We show that spectral independence implies an optimal convergence rate for a variety of MCMC algorithms.


Bio: Eric Vigoda is a Professor of Computer Science at the University of California, Santa Barbara since 2021. Previously, he was on the faculty at Georgia Tech and the University of Chicago. Vigoda completed his PhD in Computer Science from UC Berkeley in 1999.  With Mark Jerrum and Alistair Sinclair, they won a Fulkerson prize for their work on approximating the permanent of a non-negative matrix.  He is a Fellow of the American Mathematical Society.




Bio: Eric Vigoda is a Professor of Computer Science at the University of California, Santa Barbara since 2021. Previously, he was on the faculty at Georgia Tech and the University of Chicago. Vigoda completed his PhD in Computer Science from UC Berkeley in 1999.  With Mark Jerrum and Alistair Sinclair, they won a Fulkerson prize for their work on approximating the permanent of a non-negative matrix.  He is a Fellow of the American Mathematical Society.


Bio: Eric Vigoda is a Professor of Computer Science at the University of California, Santa Barbara since 2021. Previously, he was on the faculty at Georgia Tech and the University of Chicago. Vigoda completed his PhD in Computer Science from UC Berkeley in 1999.  With Mark Jerrum and Alistair Sinclair, they won a Fulkerson prize for their work on approximating the permanent of a non-negative matrix.  He is a Fellow of the American Mathematical Society.
Eric Vigoda is a Professor of Computer Science at the University of California, Santa Barbara since 2021. Previously, he was on the faculty at Georgia Tech and the University of Chicago. Vigoda completed his PhD in Computer Science from UC Berkeley in 1999.  With Mark Jerrum and Alistair Sinclair, they won a Fulkerson prize for their work on approximating the permanent of a non-negative matrix.  He is a Fellow of the American Mathematical Society.












ACO Center @ UCI • Privacy Policy • © 2022 UC Regents 






ACO Center @ UCI • Privacy Policy • © 2022 UC Regents 




ACO Center @ UCI • Privacy Policy • © 2022 UC Regents 


ACO Center @ UCI • Privacy Policy • © 2022 UC Regents 

Close Menu

Close Menu








Open toolbar

 

Open toolbar

Accessibility Tools



Increase Text 



Decrease Text 



Grayscale 



High Contrast 



Negative Contrast 



Light Background 



Links Underline 



Readable Font 




Reset





Accessibility Tools



Increase Text 



Decrease Text 



Grayscale 



High Contrast 



Negative Contrast 



Light Background 



Links Underline 



Readable Font 




Reset



Accessibility Tools

Increase Text 
Increase Text

Decrease Text 
Decrease Text

Grayscale 
Grayscale

High Contrast 
High Contrast

Negative Contrast 
Negative Contrast

Light Background 
Light Background

Links Underline 
Links Underline

Readable Font 
Readable Font


Reset

Reset