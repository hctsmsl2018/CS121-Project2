












ACO Center @ UCI  




Algorithms, Combinatorics and Optimization 













 Search





















Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 

 Menu


Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 

















Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 

 Menu


Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 














The Power of Asking More Informative Questions
Home>Seminars>The Power of Asking More Informative Questions















The Power of Asking More Informative Questions 




Date: May 23, 2019					





Time: 2:00 pm					





Room: DBH 4011					





Speaker: Shachar Lovett 					





				 (UC San Diego)					











































Abstract: In the world of big data, it is often easy to get a large amount of unlabeled data. However, learning algorithms typically require labeled data to train on. Active learning is an approach to bridge this gap, where the learning algorithm may query the labels of a few data points. The hope is that by judiciously choosing which data points to query, the number of queries can be made much smaller compared to the classical setting where all the data is labeled.
Unfortunately, this turns out to be false, even for very simple concept classes. This led research in active learning to focus on making various assumptions on the underlying data, distribution, and so on.
I will present an alternative approach: allowing the learning algorithm to ask more informative questions about the data. As I will show, even allowing very simple enriched queries, such as comparing two data points, allows in many cases to obtain exponential improvement. In addition, the mathematical tools that underlie this turn out to have surprising applications to long-standing open problems in complexity theory and discrete geometry.
Based on joint works with Max Hopkins, Daniel Kane, Gaurav Mahajan, Shay Moran and Jiapeng Zhang.



































ACO Center @ UCI • Privacy Policy • © 2022 UC Regents 

















ACO Center @ UCI  




Algorithms, Combinatorics and Optimization 













 Search





















Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 

 Menu


Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 

















Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 

 Menu


Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 














The Power of Asking More Informative Questions
Home>Seminars>The Power of Asking More Informative Questions















The Power of Asking More Informative Questions 




Date: May 23, 2019					





Time: 2:00 pm					





Room: DBH 4011					





Speaker: Shachar Lovett 					





				 (UC San Diego)					











































Abstract: In the world of big data, it is often easy to get a large amount of unlabeled data. However, learning algorithms typically require labeled data to train on. Active learning is an approach to bridge this gap, where the learning algorithm may query the labels of a few data points. The hope is that by judiciously choosing which data points to query, the number of queries can be made much smaller compared to the classical setting where all the data is labeled.
Unfortunately, this turns out to be false, even for very simple concept classes. This led research in active learning to focus on making various assumptions on the underlying data, distribution, and so on.
I will present an alternative approach: allowing the learning algorithm to ask more informative questions about the data. As I will show, even allowing very simple enriched queries, such as comparing two data points, allows in many cases to obtain exponential improvement. In addition, the mathematical tools that underlie this turn out to have surprising applications to long-standing open problems in complexity theory and discrete geometry.
Based on joint works with Max Hopkins, Daniel Kane, Gaurav Mahajan, Shay Moran and Jiapeng Zhang.



































ACO Center @ UCI • Privacy Policy • © 2022 UC Regents 














ACO Center @ UCI  




Algorithms, Combinatorics and Optimization 













 Search





















Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 

 Menu


Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 

















Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 

 Menu


Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 


















ACO Center @ UCI  




Algorithms, Combinatorics and Optimization 













 Search





















Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 

 Menu


Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 

















Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 

 Menu


Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 















ACO Center @ UCI  




Algorithms, Combinatorics and Optimization 













 Search
















ACO Center @ UCI  




Algorithms, Combinatorics and Optimization 













 Search














ACO Center @ UCI  




Algorithms, Combinatorics and Optimization 








ACO Center @ UCI  




Algorithms, Combinatorics and Optimization 






ACO Center @ UCI  




Algorithms, Combinatorics and Optimization 




ACO Center @ UCI  

ACO Center @ UCI  


Algorithms, Combinatorics and Optimization 



Algorithms, Combinatorics and Optimization 

Algorithms, Combinatorics and Optimization Algorithms, Combinatorics and Optimization







 Search















 Search













 Search











 Search









 Search






 Search



 Search
Search







Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 

 Menu


Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 













Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 

 Menu


Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 











Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 

 Menu


Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 









Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 

 Menu


Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 







Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 

 Menu


Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 





Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 

 Menu


Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 



Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 

 Menu


Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 
HomePeopleSeminar SeriesSynergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation

ICSMathBusiness SchoolIMBSEECSCenter for Algorithms and Theory of ComputationNewsContact
 Menu
MenuHomePeopleSeminar SeriesSynergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation

ICSMathBusiness SchoolIMBSEECSCenter for Algorithms and Theory of ComputationNewsContact







Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 

 Menu


Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 













Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 

 Menu


Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 











Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 

 Menu


Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 









Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 

 Menu


Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 







Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 

 Menu


Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 





Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 

 Menu


Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 



Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 

 Menu


Home
People
Seminar Series
Synergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation


News
Contact
 
HomePeopleSeminar SeriesSynergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation

ICSMathBusiness SchoolIMBSEECSCenter for Algorithms and Theory of ComputationNewsContact
 Menu
MenuHomePeopleSeminar SeriesSynergistic Units at UCI

ICS
Math
Business School
IMBS
EECS
Center for Algorithms and Theory of Computation

ICSMathBusiness SchoolIMBSEECSCenter for Algorithms and Theory of ComputationNewsContact
The Power of Asking More Informative Questions
Home>Seminars>The Power of Asking More Informative Questions
Home>HomeHome>Seminars>Seminars>The Power of Asking More Informative QuestionsThe Power of Asking More Informative Questions












The Power of Asking More Informative Questions 




Date: May 23, 2019					





Time: 2:00 pm					





Room: DBH 4011					





Speaker: Shachar Lovett 					





				 (UC San Diego)					











































Abstract: In the world of big data, it is often easy to get a large amount of unlabeled data. However, learning algorithms typically require labeled data to train on. Active learning is an approach to bridge this gap, where the learning algorithm may query the labels of a few data points. The hope is that by judiciously choosing which data points to query, the number of queries can be made much smaller compared to the classical setting where all the data is labeled.
Unfortunately, this turns out to be false, even for very simple concept classes. This led research in active learning to focus on making various assumptions on the underlying data, distribution, and so on.
I will present an alternative approach: allowing the learning algorithm to ask more informative questions about the data. As I will show, even allowing very simple enriched queries, such as comparing two data points, allows in many cases to obtain exponential improvement. In addition, the mathematical tools that underlie this turn out to have surprising applications to long-standing open problems in complexity theory and discrete geometry.
Based on joint works with Max Hopkins, Daniel Kane, Gaurav Mahajan, Shay Moran and Jiapeng Zhang.







































The Power of Asking More Informative Questions 




Date: May 23, 2019					





Time: 2:00 pm					





Room: DBH 4011					





Speaker: Shachar Lovett 					





				 (UC San Diego)					











































Abstract: In the world of big data, it is often easy to get a large amount of unlabeled data. However, learning algorithms typically require labeled data to train on. Active learning is an approach to bridge this gap, where the learning algorithm may query the labels of a few data points. The hope is that by judiciously choosing which data points to query, the number of queries can be made much smaller compared to the classical setting where all the data is labeled.
Unfortunately, this turns out to be false, even for very simple concept classes. This led research in active learning to focus on making various assumptions on the underlying data, distribution, and so on.
I will present an alternative approach: allowing the learning algorithm to ask more informative questions about the data. As I will show, even allowing very simple enriched queries, such as comparing two data points, allows in many cases to obtain exponential improvement. In addition, the mathematical tools that underlie this turn out to have surprising applications to long-standing open problems in complexity theory and discrete geometry.
Based on joint works with Max Hopkins, Daniel Kane, Gaurav Mahajan, Shay Moran and Jiapeng Zhang.





























The Power of Asking More Informative Questions 




Date: May 23, 2019					





Time: 2:00 pm					





Room: DBH 4011					





Speaker: Shachar Lovett 					





				 (UC San Diego)					











































Abstract: In the world of big data, it is often easy to get a large amount of unlabeled data. However, learning algorithms typically require labeled data to train on. Active learning is an approach to bridge this gap, where the learning algorithm may query the labels of a few data points. The hope is that by judiciously choosing which data points to query, the number of queries can be made much smaller compared to the classical setting where all the data is labeled.
Unfortunately, this turns out to be false, even for very simple concept classes. This led research in active learning to focus on making various assumptions on the underlying data, distribution, and so on.
I will present an alternative approach: allowing the learning algorithm to ask more informative questions about the data. As I will show, even allowing very simple enriched queries, such as comparing two data points, allows in many cases to obtain exponential improvement. In addition, the mathematical tools that underlie this turn out to have surprising applications to long-standing open problems in complexity theory and discrete geometry.
Based on joint works with Max Hopkins, Daniel Kane, Gaurav Mahajan, Shay Moran and Jiapeng Zhang.



























The Power of Asking More Informative Questions 




Date: May 23, 2019					





Time: 2:00 pm					





Room: DBH 4011					





Speaker: Shachar Lovett 					





				 (UC San Diego)					











































Abstract: In the world of big data, it is often easy to get a large amount of unlabeled data. However, learning algorithms typically require labeled data to train on. Active learning is an approach to bridge this gap, where the learning algorithm may query the labels of a few data points. The hope is that by judiciously choosing which data points to query, the number of queries can be made much smaller compared to the classical setting where all the data is labeled.
Unfortunately, this turns out to be false, even for very simple concept classes. This led research in active learning to focus on making various assumptions on the underlying data, distribution, and so on.
I will present an alternative approach: allowing the learning algorithm to ask more informative questions about the data. As I will show, even allowing very simple enriched queries, such as comparing two data points, allows in many cases to obtain exponential improvement. In addition, the mathematical tools that underlie this turn out to have surprising applications to long-standing open problems in complexity theory and discrete geometry.
Based on joint works with Max Hopkins, Daniel Kane, Gaurav Mahajan, Shay Moran and Jiapeng Zhang.

























The Power of Asking More Informative Questions 




Date: May 23, 2019					





Time: 2:00 pm					





Room: DBH 4011					





Speaker: Shachar Lovett 					





				 (UC San Diego)					











































Abstract: In the world of big data, it is often easy to get a large amount of unlabeled data. However, learning algorithms typically require labeled data to train on. Active learning is an approach to bridge this gap, where the learning algorithm may query the labels of a few data points. The hope is that by judiciously choosing which data points to query, the number of queries can be made much smaller compared to the classical setting where all the data is labeled.
Unfortunately, this turns out to be false, even for very simple concept classes. This led research in active learning to focus on making various assumptions on the underlying data, distribution, and so on.
I will present an alternative approach: allowing the learning algorithm to ask more informative questions about the data. As I will show, even allowing very simple enriched queries, such as comparing two data points, allows in many cases to obtain exponential improvement. In addition, the mathematical tools that underlie this turn out to have surprising applications to long-standing open problems in complexity theory and discrete geometry.
Based on joint works with Max Hopkins, Daniel Kane, Gaurav Mahajan, Shay Moran and Jiapeng Zhang.






















The Power of Asking More Informative Questions 




Date: May 23, 2019					





Time: 2:00 pm					





Room: DBH 4011					





Speaker: Shachar Lovett 					





				 (UC San Diego)					












The Power of Asking More Informative Questions 




Date: May 23, 2019					





Time: 2:00 pm					





Room: DBH 4011					





Speaker: Shachar Lovett 					





				 (UC San Diego)					










The Power of Asking More Informative Questions 




Date: May 23, 2019					





Time: 2:00 pm					





Room: DBH 4011					





Speaker: Shachar Lovett 					





				 (UC San Diego)					








The Power of Asking More Informative Questions 




Date: May 23, 2019					





Time: 2:00 pm					





Room: DBH 4011					





Speaker: Shachar Lovett 					





				 (UC San Diego)					






The Power of Asking More Informative Questions 




Date: May 23, 2019					





Time: 2:00 pm					





Room: DBH 4011					





Speaker: Shachar Lovett 					





				 (UC San Diego)					




The Power of Asking More Informative Questions 

The Power of Asking More Informative Questions 


Date: May 23, 2019					



Date: May 23, 2019					

Date: May 23, 2019					


Time: 2:00 pm					



Time: 2:00 pm					

Time: 2:00 pm					


Room: DBH 4011					



Room: DBH 4011					

Room: DBH 4011					


Speaker: Shachar Lovett 					



Speaker: Shachar Lovett 					

Speaker: Shachar Lovett 					


				 (UC San Diego)					



				 (UC San Diego)					

				 (UC San Diego)					































































































































Abstract: In the world of big data, it is often easy to get a large amount of unlabeled data. However, learning algorithms typically require labeled data to train on. Active learning is an approach to bridge this gap, where the learning algorithm may query the labels of a few data points. The hope is that by judiciously choosing which data points to query, the number of queries can be made much smaller compared to the classical setting where all the data is labeled.
Unfortunately, this turns out to be false, even for very simple concept classes. This led research in active learning to focus on making various assumptions on the underlying data, distribution, and so on.
I will present an alternative approach: allowing the learning algorithm to ask more informative questions about the data. As I will show, even allowing very simple enriched queries, such as comparing two data points, allows in many cases to obtain exponential improvement. In addition, the mathematical tools that underlie this turn out to have surprising applications to long-standing open problems in complexity theory and discrete geometry.
Based on joint works with Max Hopkins, Daniel Kane, Gaurav Mahajan, Shay Moran and Jiapeng Zhang.




















Abstract: In the world of big data, it is often easy to get a large amount of unlabeled data. However, learning algorithms typically require labeled data to train on. Active learning is an approach to bridge this gap, where the learning algorithm may query the labels of a few data points. The hope is that by judiciously choosing which data points to query, the number of queries can be made much smaller compared to the classical setting where all the data is labeled.
Unfortunately, this turns out to be false, even for very simple concept classes. This led research in active learning to focus on making various assumptions on the underlying data, distribution, and so on.
I will present an alternative approach: allowing the learning algorithm to ask more informative questions about the data. As I will show, even allowing very simple enriched queries, such as comparing two data points, allows in many cases to obtain exponential improvement. In addition, the mathematical tools that underlie this turn out to have surprising applications to long-standing open problems in complexity theory and discrete geometry.
Based on joint works with Max Hopkins, Daniel Kane, Gaurav Mahajan, Shay Moran and Jiapeng Zhang.


















Abstract: In the world of big data, it is often easy to get a large amount of unlabeled data. However, learning algorithms typically require labeled data to train on. Active learning is an approach to bridge this gap, where the learning algorithm may query the labels of a few data points. The hope is that by judiciously choosing which data points to query, the number of queries can be made much smaller compared to the classical setting where all the data is labeled.
Unfortunately, this turns out to be false, even for very simple concept classes. This led research in active learning to focus on making various assumptions on the underlying data, distribution, and so on.
I will present an alternative approach: allowing the learning algorithm to ask more informative questions about the data. As I will show, even allowing very simple enriched queries, such as comparing two data points, allows in many cases to obtain exponential improvement. In addition, the mathematical tools that underlie this turn out to have surprising applications to long-standing open problems in complexity theory and discrete geometry.
Based on joint works with Max Hopkins, Daniel Kane, Gaurav Mahajan, Shay Moran and Jiapeng Zhang.
















Abstract: In the world of big data, it is often easy to get a large amount of unlabeled data. However, learning algorithms typically require labeled data to train on. Active learning is an approach to bridge this gap, where the learning algorithm may query the labels of a few data points. The hope is that by judiciously choosing which data points to query, the number of queries can be made much smaller compared to the classical setting where all the data is labeled.
Unfortunately, this turns out to be false, even for very simple concept classes. This led research in active learning to focus on making various assumptions on the underlying data, distribution, and so on.
I will present an alternative approach: allowing the learning algorithm to ask more informative questions about the data. As I will show, even allowing very simple enriched queries, such as comparing two data points, allows in many cases to obtain exponential improvement. In addition, the mathematical tools that underlie this turn out to have surprising applications to long-standing open problems in complexity theory and discrete geometry.
Based on joint works with Max Hopkins, Daniel Kane, Gaurav Mahajan, Shay Moran and Jiapeng Zhang.














Abstract: In the world of big data, it is often easy to get a large amount of unlabeled data. However, learning algorithms typically require labeled data to train on. Active learning is an approach to bridge this gap, where the learning algorithm may query the labels of a few data points. The hope is that by judiciously choosing which data points to query, the number of queries can be made much smaller compared to the classical setting where all the data is labeled.
Unfortunately, this turns out to be false, even for very simple concept classes. This led research in active learning to focus on making various assumptions on the underlying data, distribution, and so on.
I will present an alternative approach: allowing the learning algorithm to ask more informative questions about the data. As I will show, even allowing very simple enriched queries, such as comparing two data points, allows in many cases to obtain exponential improvement. In addition, the mathematical tools that underlie this turn out to have surprising applications to long-standing open problems in complexity theory and discrete geometry.
Based on joint works with Max Hopkins, Daniel Kane, Gaurav Mahajan, Shay Moran and Jiapeng Zhang.












Abstract: In the world of big data, it is often easy to get a large amount of unlabeled data. However, learning algorithms typically require labeled data to train on. Active learning is an approach to bridge this gap, where the learning algorithm may query the labels of a few data points. The hope is that by judiciously choosing which data points to query, the number of queries can be made much smaller compared to the classical setting where all the data is labeled.
Unfortunately, this turns out to be false, even for very simple concept classes. This led research in active learning to focus on making various assumptions on the underlying data, distribution, and so on.
I will present an alternative approach: allowing the learning algorithm to ask more informative questions about the data. As I will show, even allowing very simple enriched queries, such as comparing two data points, allows in many cases to obtain exponential improvement. In addition, the mathematical tools that underlie this turn out to have surprising applications to long-standing open problems in complexity theory and discrete geometry.
Based on joint works with Max Hopkins, Daniel Kane, Gaurav Mahajan, Shay Moran and Jiapeng Zhang.




Abstract: In the world of big data, it is often easy to get a large amount of unlabeled data. However, learning algorithms typically require labeled data to train on. Active learning is an approach to bridge this gap, where the learning algorithm may query the labels of a few data points. The hope is that by judiciously choosing which data points to query, the number of queries can be made much smaller compared to the classical setting where all the data is labeled.
Unfortunately, this turns out to be false, even for very simple concept classes. This led research in active learning to focus on making various assumptions on the underlying data, distribution, and so on.
I will present an alternative approach: allowing the learning algorithm to ask more informative questions about the data. As I will show, even allowing very simple enriched queries, such as comparing two data points, allows in many cases to obtain exponential improvement. In addition, the mathematical tools that underlie this turn out to have surprising applications to long-standing open problems in complexity theory and discrete geometry.
Based on joint works with Max Hopkins, Daniel Kane, Gaurav Mahajan, Shay Moran and Jiapeng Zhang.


Abstract: In the world of big data, it is often easy to get a large amount of unlabeled data. However, learning algorithms typically require labeled data to train on. Active learning is an approach to bridge this gap, where the learning algorithm may query the labels of a few data points. The hope is that by judiciously choosing which data points to query, the number of queries can be made much smaller compared to the classical setting where all the data is labeled.
Unfortunately, this turns out to be false, even for very simple concept classes. This led research in active learning to focus on making various assumptions on the underlying data, distribution, and so on.
I will present an alternative approach: allowing the learning algorithm to ask more informative questions about the data. As I will show, even allowing very simple enriched queries, such as comparing two data points, allows in many cases to obtain exponential improvement. In addition, the mathematical tools that underlie this turn out to have surprising applications to long-standing open problems in complexity theory and discrete geometry.
Based on joint works with Max Hopkins, Daniel Kane, Gaurav Mahajan, Shay Moran and Jiapeng Zhang.
In the world of big data, it is often easy to get a large amount of unlabeled data. However, learning algorithms typically require labeled data to train on. Active learning is an approach to bridge this gap, where the learning algorithm may query the labels of a few data points. The hope is that by judiciously choosing which data points to query, the number of queries can be made much smaller compared to the classical setting where all the data is labeled.Unfortunately, this turns out to be false, even for very simple concept classes. This led research in active learning to focus on making various assumptions on the underlying data, distribution, and so on.I will present an alternative approach: allowing the learning algorithm to ask more informative questions about the data. As I will show, even allowing very simple enriched queries, such as comparing two data points, allows in many cases to obtain exponential improvement. In addition, the mathematical tools that underlie this turn out to have surprising applications to long-standing open problems in complexity theory and discrete geometry.informativeBased on joint works with Max Hopkins, Daniel Kane, Gaurav Mahajan, Shay Moran and Jiapeng Zhang.





















ACO Center @ UCI • Privacy Policy • © 2022 UC Regents 






ACO Center @ UCI • Privacy Policy • © 2022 UC Regents 




ACO Center @ UCI • Privacy Policy • © 2022 UC Regents 


ACO Center @ UCI • Privacy Policy • © 2022 UC Regents 

Close Menu

Close Menu








Open toolbar

 

Open toolbar

Accessibility Tools



Increase Text 



Decrease Text 



Grayscale 



High Contrast 



Negative Contrast 



Light Background 



Links Underline 



Readable Font 




Reset





Accessibility Tools



Increase Text 



Decrease Text 



Grayscale 



High Contrast 



Negative Contrast 



Light Background 



Links Underline 



Readable Font 




Reset



Accessibility Tools

Increase Text 
Increase Text

Decrease Text 
Decrease Text

Grayscale 
Grayscale

High Contrast 
High Contrast

Negative Contrast 
Negative Contrast

Light Background 
Light Background

Links Underline 
Links Underline

Readable Font 
Readable Font


Reset

Reset